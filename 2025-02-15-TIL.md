# GIT TIL 56 - LLM의 발전과 신경망의 진화

 <br> <br>


곧 있을 조별 과제 제출까지 LLM 특강 학습한 내용 정리할 겸 <br>
 배운 내용을 계속 복습해야겠다.  <br> 

 <br>

## 선형 모델에서 RNN까지

처음에는 단순한 선형 모델로 시작했다. <br><br> 
입력값에 가중치를 곱하고 편향을 더하는 단순한 구조였는데, <br> 
이게 지금 거대 언어 모델의 시작점이라니 신기하다. <br><br>
마치 아기가 걸음마를 배우는 것처럼, AI도 이런 단순한 구조에서 시작했다가 지금은 어느정도 커진 걸까?

 <br>

특강의 시작은 RNN(순환 신경망)에 대해 다시 한번 다루어주었고, 이전 정보를 기억하면서 다음 예측을 한다는 개념이 매력적이다. <br><br> 
뭐 이미 우리가 GPT 모델을 써오면서 이제는 당연하가도 느끼는 이 기억 장치에도 처음엔 문제가 많았다. <br> <br>

### 바로 '장기 의존성 문제' 
 - 문장이 길어질수록 앞부분의 정보를 잃어버리는 현상 
<br><br>

>마치 우리가 긴 문장을 읽을 때 앞부분을 잊어버리는 것처럼 말이다. 😥

 <br><br>

## Transformer의 혁신

그러다 2017년에 구글이 Transformer라는 걸 내놓았는데, 이건 정말 게임 체인저다. <br><br> 
RNN의 장기 의존성 문제를 해결했을 뿐만 아니라, 문장의 모든 부분을 동시에 처리할 수 있게 되었다. <br><br> 
근데 이걸 학습시키려면 엄청난 컴퓨팅 파워가 필요하다고 한다... <br>
한번 돌리는 데 드는 비용이 상상을 초월한다니, 실제 금액을 보고나니 <br> 
왜 아직 발전 단계라는 건지 단번에 이해했다..! <br>

![Image](https://github.com/user-attachments/assets/c51cadbf-9c99-4930-b562-9a4a5bdd7f5a)

<br>

## LLM과 프롬프트의 혁명

가장 흥미로웠던 건 LLM에서의 프롬프트 엔지니어링이다. <br> 예전에는 모델에게 단순히 질문만 하는 수준이었는데, <br>
이제는 맥락을 주고 역할을 부여하고 제약조건을 걸 수도 있다. <br><br>

>마치 전문가와 대화하듯이 AI와 소통할 수 있게 된 거다!

<br><br>
특히 'few-shot learning'이라고 해서, 몇 가지 예시만 들어주면 AI가 패턴을 파악하고 비슷한 작업을 수행할 수 있다는 게 신기했다. <br><br>
 이건 마치 사람이 몇 가지 예시만 보고도 패턴을 파악하는 것과 비슷해 보였다.
 <br>

 예를 들어보자!

 ![Image](https://github.com/user-attachments/assets/e2b940b8-f031-4676-9c9d-8616bf9322cc)

> 나는 빨간 사과를 원했는데..

 <br>

그럼 아래와 같은 방법은?

```
Q: 바나나는 무슨색인가요?
A: 노란색 입니다.

Q: 포도는 무슨색인가요?
A: 보라색 입니다.

Q: 사과는 무슨색인가요?
```
![Image](https://github.com/user-attachments/assets/97c68f4c-dfae-45ff-8036-c13f47b09cca)

이러면 “빨간색 입니다.”와 같은 내가 원하는 답변이 나올 ‘확률’이 높아진다.


 <br> <br>

## 이런 발전 과정을 보면서 든 생각은..
 AI가 점점 더 인간의 학습 방식을 닮아가고 있다는 거다. <br> <br>
 단순한 패턴 매칭에서 시작해서,<br>
  이제는 맥락을 이해하고 창의적인 답변도 할 수 있게 되었으니까.

다음에는 이 LLM들이 어떻게 학습되는지,<br>
특히 GPT나 BERT 같은 모델들의 내부 구조를 더 자세히 배워 볼텐데 조별 과제와 최종 프로젝트때는 내 로컬 환경에서도 원활하게 돌아갈 수 있을까..<br><br>
이 엄청난 컴퓨팅 파워를 어떻게 최적화할 수 있을까 궁금해진다..

<br><br>

---

<br><br>