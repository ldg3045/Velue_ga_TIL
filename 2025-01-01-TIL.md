# Git TIL 13

<br><br>

# 딥러닝 기초 학습

<br>

## 1. 딥러닝이란?
* 인공신경망을 기반으로 하는 기계학습의 한 분야
* 여러 층의 신경망을 통해 데이터의 특징을 자동으로 학습
* 인간의 뇌의 뉴런 구조를 모방한 알고리즘

<br>

## 2. 기본 구성 요소
### 2.1 뉴런 (Neuron)
* 입력값을 받아 가중치를 곱하고 편향을 더함
* 활성화 함수를 통과시켜 출력값 생성

<br>

### 2.2 활성화 함수 (Activation Function)
* ReLU: max(0,x) - 가장 많이 사용됨
* Sigmoid: 1/(1+e^(-x))
* tanh: (e^x - e^(-x))/(e^x + e^(-x))

<br>

### 2.3 층(Layer)
* 입력층: 데이터 입력
* 은닉층: 데이터 처리
* 출력층: 결과 출력

## 3. 학습 과정
1. 순전파 (Forward Propagation)
2. 손실 함수 계산 (Loss Function)
3. 역전파 (Backward Propagation)
4. 가중치 업데이트 (Weight Update)

<br>

## 4. 주요 프레임워크

```python
import tensorflow as tf # 텐서플로우 임포트

model = tf.keras.Sequential([ # 모델 생성
    tf.keras.layers.Dense(128, activation='relu'), # 은닉층 1
    tf.keras.layers.Dense(64, activation='relu'), # 은닉층 2
    tf.keras.layers.Dense(10, activation='softmax') # 출력층
]) 
``` 

<br>


## 5. 주요 개념
### 5.1 하이퍼파라미터
* 학습률 (Learning Rate)
* 배치 크기 (Batch Size)
* 에포크 (Epoch)
* 드롭아웃 비율 (Dropout Rate)

<br>

### 5.2 최적화 알고리즘
* SGD (Stochastic Gradient Descent)
* Adam
* RMSprop

<br>

## 6. 딥러닝 모델 종류
### 6.1 CNN (Convolutional Neural Network)
* 이미지 처리에 특화
* 컨볼루션 층과 풀링 층 사용

<br>

### 6.2 RNN (Recurrent Neural Network)
* 시계열 데이터 처리
* LSTM, GRU 등의 변형 존재

<br>

### 6.3 Transformer
* 자연어 처리의 혁신
* 어텐션 메커니즘 사용

<br>

---

